{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.models.optical_flow import raft_large\n",
    "\n",
    "# Path load\n",
    "outputs_path = 'sample_output'\n",
    "gt_path = 'sample_gt'\n",
    "outputs = sorted([os.path.join(outputs_path, output) for output in os.listdir(outputs_path)])\n",
    "gts = sorted([os.path.join(gt_path, gt) for gt in os.listdir(gt_path)])\n",
    "\n",
    "# Device setting\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Save option\n",
    "save_folder = 'save'\n",
    "save_image = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocess\n",
    "def preprocess(batch):\n",
    "    transforms = T.Compose(\n",
    "        [   \n",
    "            T.ToTensor(),\n",
    "            T.ConvertImageDtype(torch.float32),\n",
    "            T.Normalize(mean=0.5, std=0.5),  # map [0, 1] into [-1, 1]\n",
    "            T.Resize(size=(520, 960)), # Resize to a size supported by RAFT\n",
    "        ]\n",
    "    )\n",
    "    batch = transforms(batch)\n",
    "    return batch\n",
    "\n",
    "\n",
    "# Warp function\n",
    "def warp_feature(x, flow):\n",
    "    \"\"\"\n",
    "    x: (B, C, H, W)\n",
    "    flow: (B, 2, H, W) - (u, v) shape optical flow\n",
    "        Convert the flow into a normalized grid with values in the range [-1, 1].\n",
    "    \"\"\"\n",
    "    B, C, H, W = x.size()\n",
    "    # generate index grid\n",
    "    # normalized coords: -1 ~ 1 range\n",
    "    y, x_ = torch.meshgrid(\n",
    "        torch.linspace(-1, 1, H, device=x.device),\n",
    "        torch.linspace(-1, 1, W, device=x.device)\n",
    "    )\n",
    "    # (H, W) -> (B, H, W)\n",
    "    grid = torch.stack((x_, y), dim=-1).unsqueeze(0).repeat(B, 1, 1, 1)\n",
    "    # Separate the flow into its horizontal (u) and vertical (v) components.\n",
    "    flow_u = flow[:, 0, :, :]  # (B, H, W)\n",
    "    flow_v = flow[:, 1, :, :]  # (B, H, W)\n",
    "\n",
    "    # Assume that flow_u and flow_v are normalized to the range [â€“1, 1].\n",
    "    grid[:, :, :, 0] += flow_u\n",
    "    grid[:, :, :, 1] += flow_v\n",
    "\n",
    "    return F.grid_sample(x, grid, mode='bilinear', padding_mode='zeros', align_corners=True)\n",
    "\n",
    "\n",
    "def flow_normalize(x):\n",
    "    B, _, _, _ = x.shape\n",
    "    max_ = torch.tensor([[[520]], [[960]]], device='cuda:0').repeat(B, 1, 1, 1)\n",
    "    x_norm = 2 * (-x + max_) / (2 * max_ + 1e-8) - 1\n",
    "    return x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total L1 loss : tensor(0.1602)\n"
     ]
    }
   ],
   "source": [
    "# Model load\n",
    "model = raft_large(pretrained=True, progress=False).to(device)\n",
    "model = model.eval()\n",
    "\n",
    "# Compute optical flow and warp images\n",
    "total_loss = []\n",
    "for i in range(len(gts)):\n",
    "    # RAFT only supports color images so repeat the gray image across three channels.\n",
    "    outputs_batch = preprocess(Image.open(outputs[i])).repeat(1, 3, 1, 1).to(device)\n",
    "    gts_batch = preprocess(Image.open(gts[i])).repeat(1, 3, 1, 1).to(device)\n",
    "    mask = torch.ones_like(outputs_batch)\n",
    "    with torch.no_grad():\n",
    "        list_of_flows = model(outputs_batch, gts_batch)\n",
    "    flow = list_of_flows[-1]\n",
    "    flow_normalized = flow_normalize(flow)\n",
    "    x = torch.mean(warp_feature(outputs_batch, flow_normalized), dim=1)\n",
    "    mask = torch.mean(warp_feature(mask, flow_normalized), dim=1)\n",
    "    gts_batch = torch.mean(gts_batch, dim=1) * (mask > 0.5)\n",
    "    total_loss.append(F.l1_loss(gts_batch, x))\n",
    "\n",
    "    if save_image:\n",
    "        x_ = ((x.squeeze(0) * 0.5 + 0.5).clamp(0, 1) * 255).detach().to(torch.uint8).cpu().numpy()\n",
    "        x_ = cv2.resize(x_, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "        x_ = Image.fromarray(x_, mode='L')\n",
    "        os.makedirs(save_folder, exist_ok=True)\n",
    "        x_.save(f'{save_folder}/tmp_{i}.png')\n",
    "print('Total L1 loss :', torch.mean(torch.tensor(total_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hynix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
